<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[zabbix3.4安装部署]]></title>
    <url>%2F2017%2F12%2F12%2Fzabbix3-4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[运行环境： 12345nginx-1.12.1mysql-5.5.56php-7.1.7Ubuntu 16.04Linux localhost 4.9.50-x86_64 前言Linux下常用的系统监控软件有Nagios、Cacti、Zabbix、Monit等，这些开源的软件，可以帮助我们更好的管理机器，在第一时间内发现，并警告系统维护人员。 使用Zabbix的目的，是为了能够更好的监控mysql数据库服务器，并且能够生成图形报表，虽然Nagios也能够生成图形报表，但没有Zabbix这么强大。 Zabbix简介 zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。 zabbix由zabbix server与可选组件zabbix agent两部门组成。 zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视。 zabbix agent需要安装在被监视的目标服务器上，它主要完成对硬件信息或与操作系统有关的内存，CPU等信息的收集。 zabbix的主要特点： 安装与配置简单，学习成本低 支持多语言（包括中文） 免费开源 自动发现服务器与网络设备 分布式监视以及WEB集中管理功能 可以无agent监视 用户安全认证和柔软的授权方式 通过WEB界面设置或查看监视结果 email等通知功能 Zabbix主要功能 CPU负荷 内存使用 磁盘使用 网络状况 端口监视 日志监视 Zabbix安装 zabbix WEB环境搭建 zabbix的安装需要LAMP或者LNMP环境。 zabbix 数据库设置 zabbix数据库可以和zabbix服务器分离，采用用专门的mysql服务器存储数据，此时要给zabbix数据库受相应的权限。 对于Zabbix server 和 proxy 守护进程以及Zabbix前端，都需要连接到一个数据库。Zabbix agent不需要数据库的支持。 SQL 脚本 用于创建数据库架构（schema）并插入数据集（dataset）。 Zabbix proxy数据库只需要数据库架构（schema），而Zabbix server数据库在建立数据库架构（schema）后，还需要数据集（dataset）。 建立Zabbix数据库后，可以开始对Zabbix进行编译。 1grant all privileges on zabbix.* to zabbix_user@&apos;ip&apos; identified by &apos;123456&apos;; == 注：ip为zabbix服务器的IP地址。== 关于数据库的安装，可以查看Mysql安装，我习惯使用二进制包。 启动数据库 1/usr/local/mysql/bin/mysqld_safe --user=mysql &amp; 登录数据库，创建帐号和设置权限： 123mysql&gt; use mysql;mysql&gt;create database zabbix character set utf8;mysql&gt;grant all privileges on zabbix.* to zabbix_user@&apos;localhost&apos; identified by &apos;123456&apos;; 安装zabbix服务 增加zabbix用户和组 对于所有Zabbix的守护进程，需要一个无特权的用户。如果Zabbix守护进程以一个无特权的用户账户启动，那么它会使用该用户运行。 然而，如果一个守护进程以‘root’用户启动，它会切换为‘zabbix’用户账户，且这个用户必须存在。在Linux系统中，可以使用下面命令建立一个用户（该用户属于自己的用户组，“zabbix”）： 12#groupadd zabbix#useradd -g zabbix -m zabbix 使用root，bin或其他特殊权限的账户运行Zabbix是一个安全风险。 对于Zabbix前端的安装，不需要使用单独的用户账户。 如果Zabbix server 和 agent 运行在同一台计算机上，建议使用不同的账户运行Server和Agent。否则，如果两个进程使用了同一个用户，Agent就可以访问Server的配置文件，并可轻易地读取Zabbix中任何管理员级别的用户，比如数据库密码。 官网下载解压软件包。 在 Ubuntu 14.04 LTS 上安装 Zabbix 3.4： 1wget http://repo.zabbix.com/zabbix/3.4/ubuntu/pool/main/z/zabbix/zabbix_3.4.4.orig.tar.gz 导入数据库表 12345create user &apos;zabbix&apos;@&apos;localhost&apos; identified by &apos;PASSWORD&apos;;create database zabbix;grant all privileges on `zabbix`.* to &apos;zabbix&apos;@&apos;localhost&apos;;flush privileges;exit; 1234567891011121314151617#cd zabbix-3.4/database/mysqlmysql -u root -p mysql&gt; use zabbix; #进入数据库，按照顺序进行导入，否则会出错。Database changedmysql&gt; source ~/zabbix-3.4.4/database/mysql/schema.sql...Query OK, 0 rows affected (0.05 sec)Records: 0 Duplicates: 0 Warnings: 0 mysql&gt; source ~/zabbix-3.4.4/database/mysql/images.sql... Query OK, 1 row affected (0.01 sec) mysql&gt; source ~/zabbix-3.4.4/database/mysql/data.sql 编译安装zabbix 1./configure --prefix=/usr/local/zabbix --with-mysql=/usr/local/mysql/bin/mysql_config --with-net-snmp --with-libcurl --enable-server --enable-agent --enable-proxy 添加服务端口 (可选步骤) 12345vim /etc/serviceszabbix-agent 10050/tcp # Zabbix Agentzabbix-agent 10050/udp # Zabbix Agentzabbix-trapper 10051/tcp # Zabbix Trapperzabbix-trapper 10051/udp # Zabbix Trapper 添加配置文件 123mkdir -p /etc/zabbixcp -r zabbix-3.4/conf/* /etc/zabbix/chown -R zabbix:zabbix /etc/zabbix 修改server配置文件，添加zabbix数据库密码 1vim /etc/zabbix/zabbix_server.conf 1234567891011LogFile=/tmp/zabbix_server.logPidFile=/tmp/zabbix_server.pidDBName=zabbixDBUser=zabbix_userDBPassword=123456 #指定zabbix数据库密码ListenIP=192.168.10.197 #服务器IP地址 修改Agentd配置文件，更改HOSTNAME为本机的hostname 1vim /etc/zabbix/zabbix_agentd.conf 123456789PidFile=/tmp/zabbix_agentd.pid #进程PIDLogFile=/tmp/zabbix_agentd.log #日志保存位置EnableRemoteCommands=1 #允许执行远程命令Server=192.168.10.197 #agent端的ipHostname=client1 #必须与zabbix创建的host name相同 添加web前段php文件 123cd zabbix-3.4/frontends/cp -rf php /home/httpd/zabbix #虚拟主机目录chown -R zabbix:zabbix zabbix web前端安装配置 修改PHP相关参数 1vim php.ini 123456max_execution_time = 300max_input_time = 300memory_limit = 128Mpost_max_size = 32Mdate.timezone = Asia/Shanghaimbstring.func_overload=2 PHP还必须支持一下模块，在php源码包直接编译安装。详细模块需要在安装是会提示:bcmath.so、gettext.so 在客户端浏览器上面访问zabbix，开始WEB的前端配置，http://ZabbixIP/zabbix 按提示点击下一步 Step1：下一步。Step2：如果全部OK的话才能进行下一步的安装，如果有错误请返回到server端检查相关的软件包是否安装。Step3：需要输入mysql数据库帐号密码,如果数据库不在zabbix服务器上面，在Host里面添加数据库服务器的地址，并且要用grant命令给数据库授权。Step4：输入服务器端 host name or host IP addres； 最后会自动写入配置文件：zabbix.conf.php，配置完成后出现登陆界面，默认的用户名为：admin，密码为：zabbix。 Now we’ll add a user for Zabbix to run as. We’ll configure scripts to control the zabbix server daemon. 12345678910111213[Unit]Description=Zabbix ServerAfter=syslog.target network.target mysqld.service[Service]Type=oneshotExecStart=/usr/local/zabbix/sbin/zabbix_server -c /usr/local/zabbix/etc/zabbix_server.confExecReload=/usr/local/zabbix/sbin/zabbix_server -R config_cache_reloadRemainAfterExit=yesPIDFile=/var/run/zabbix/zabbix_server.pid[Install]WantedBy=multi-user.target 启动zabbix服务在zabbix安装目录下面可以直接启动 123#/usr/local/zabbix/sbin/zabbix_server starttcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 7140/zabbix_agentd 设置开启自动启动1vim /etc/rc.d/rc.local 最后添加下面两行 12/usr/local/zabbix/sbin/zabbix_server start/usr/local/zabbix/sbin/zabbix_agentd start 至此，zabbix server端的安装完毕，我们可以通过浏览器来访问! Zabbix主要的配置文件两个:“zabbix_server.conf”负责服务器端的设定； zabbix_agent.conf”用来设置客户端代理参数；“zabbix_proxy.conf”用来设定分布式的部署。 Zabbix_server.conf参数除了保证服务正常运行外还涉及该服务器的性能，如果参数设定不合理可能会导致zabbix添加主机不正常、代理端数据无法正常收集或是zabbix服务器性能严重下降，经常报告CPU占用过高或是IO占用过高等问题。 Zabbix前端已经就绪！默认的用户名是Admin，密码是zabbix。 跳坑 从布署包安装 zabbix的时候，影响到了mysql.导导致mysql启动不起来！运行下面的命令之后，即可！ 1/usr/local/mysql/bin/mysqld_safe 还有就是布署包默认运行的是appace容器，但是我的服务器上面已经有nginx了。所以最后还是手动编译一下。 apt-get install zabbix-server-mysql zabbix-frontend-php 通过这种方式安装zabbix的时候，出现了一个问题就是重启lnmp 时，mysql不能正常启动 3.configure: error: Invalid Net-SNMP directory - unable to find net-snmp-config 解决方法1apt-get install libsnmp-dev 编译安装zabbix error: MySQL library not found 123find / -name &quot;mysql_config*&quot;/usr/local/mysql/bin/mysql_config 我把–with-mysql改成 1--with-mysql=/usr/local/mysql/bin/mysql_config 正常通过 15. PHP Parse error: syntax error, unexpected &apos;[&apos; in /var/www/html/index.php on line 29 1PHP 5.4 is required 参考文档1 zabbix-3.0.4安装部署 官方从部署包安装zabbix Installing Zabbix 3.0 on Ubuntu 16.04 在Ubuntu 上安装 Zabbix Zabbix Documentation 3.4 How to Install Zabbix Server 3.0 on Ubuntu 16.04/14.04 LTS and Debian 8/7]]></content>
      <categories>
        <category>安全运维</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[puppet系统配置自动化解决方案(转)]]></title>
    <url>%2F2017%2F12%2F10%2Fpuppet%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E8%87%AA%E5%8A%A8%E5%8C%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[相信做过运维的朋友都会有这样的体会：把一个新的服务器从刚装好系统的状态配置到可以运行应用程序，是个挺麻烦的过程。 就拿一个运行 nginx + php 的 web 服务器为例，可能需要部署 ssh 公钥，设置用户 sudo 权限，关闭密码登录、root 远程登录，配置 iptables 规则。然后安装所需版本的 nginx、 php 到规范的路径，不能搞错版本，以免缺失所需特性或者造成冲突，还要安装应用所需要的 php 扩展比如 gd 之类。 然后是用于监控的客户端程序，比如 nagios 的 nrpe ，或者 zabbix_agent，用于日志轮转的 cronolog 等等。最后还得记得修改 ulimits 、tcp 相关的内核参数。然后还得一一验证所有的设置是否正确。如果是部署了新的东西或者更新了配置，还得写一下安装文档，这样下回安装的时候才不会遗漏什么编译 选项、软件包，或者少设置了系统参数导致故障。 有人请假或则离职的时候，别人也才能接替。需要部署的还不会仅仅是 web 服务器，还有 lvs 、mysql、memcache，也许还会有 redis、sphinx 等等等等。有软件包需要升级，也得对所有用到的机器都升级一遍。更要命的是，往往需要配置的还不是一台机器，而是十几台乃至上百台。 这里可以看出，系统配置本身是件很繁琐的事情。 需要考虑到很多方面的事情，任何一个地方出了纰漏就可能导致故障或者埋下隐患。手动来做很容易出错，也很不够敏 捷高效，难以快速响应需求。为了解决这些问题，我也曾经用 bash 做过一些脚本，来实现部署和系统设置的自动化，但是受到 bash 的表达能力的限制，脚本的编写测试维护并不轻松。 我们碰到的麻烦别人也会碰到。所以就有了自动化好在现在有了一个好用的工具来解决这些问题。 puppet就是这样一个功能强大的系统配置集群管理工具。puppet分为 master端和agent 端，可以实现分布式分发，有强大的配置管理功能，可以实现自动化分发文件、安装软件包、执行命令、添加系统用户、设置 crontab 等等。它的配置文件是一种表达能力强的 DSL，可读性好、容易复用，且本身就可以作为很好的文档，这就免除了维护文档的负担，也避免了文档过时的问题。 puppet还使用了ssl 来保证通讯的安全性，防止敏感的配置信息泄露。支持集群化，以实现大批量主机并行更新维护。引入的 factor 还实现了针对不同系统、不同发行版、不同环境的针对性设置。以及很多方便强大的功能。 我们先看看如何安装 puppet 。最方便的方法是使用包管理器。对于 centos 等 redhat 系发行版，可以通过 yum 来安装。先把 puppet 的官方源加入到系统中： 1234567891011121314# cat &gt; /etc/yum.repos.d/puppet.repo &lt;&lt; EOF[puppet-dependencies]name=puppet dependenciesbaseurl=http://yum.puppetlabs.com/el/\$releasever/dependencies/\$basearch/gpgcheck=1gpgkey=http://yum.puppetlabs.com/RPM-GPG-KEY-puppetlabs[puppet-products]name=puppet dependenciesbaseurl=http://yum.puppetlabs.com/el/\$releasever/products/\$basearch/gpgcheck=1gpgkey=http://yum.puppetlabs.com/RPM-GPG-KEY-puppetlabsEOF 然后 1yum install puppet 就会自动安装好 puppet。从所列出依赖的软件包可以看出， puppet 是用 ruby 实现的。对于 debian 系发行版，也可以在 apt.puppetlabs.com 中找到相应的源和 gpg key。 puppet 分为 master 和 agent 。找两台机器或者两个虚拟机，一台作为 master，一台作为 agent ，两端都安装好后就可以开始配置了。 首先配置 master 。先在 master 端运行一下 1puppet master 初次运行会生成puppet 用户， 在 /etc/puppet 目录下生成默认配置目录结构并在 /var/lib/puppet 生成数据文件。如果提示 permisiton denided ，可以试试 chown puppet:puppet /var/lib/puppet/run 。 然后我们就可以开始写第一个配置文件了。在 /etc/puppet/manifests 目录下建一个 site.pp ，这是 puppet master 的主配置文件。输入 1234567package &#123; &quot;bison&quot;: ensure=&gt;&quot;installed&quot;,&#125;exec &#123; &quot;puppet test&quot;: command=&gt;&quot;/bin/touch /tmp/puppet-test&quot;,&#125; 第一个配置会使 agent 端确保编译 php 所必须的软件包 bison 已经安装好。对于不同的系统，会使用各自的包管理器来安装。第二个配置会在 agent 端执行 /bin/touch /tmp/puppet-test 。 然后配置客户端。先编辑 /etc/hosts，加入 master 的 ip，如： 1192.168.1.101 puppet 在客户端运行一下 1puppet agent --test 初次运行也同样会生成客户端的相应文件，然后就会去连接 master 端执行任务。此时会提示 1warning: peer certificate won&apos;t be verified in this SSL session exiting; no certificate found and waitforcert is disabled 这表示 agent 需要认证。因为 puppet 使用了 ssl 来保证安全，并需要 agent 经过 master 认证才能够访问配置。到 master 端执行一下 1puppet cert list 会列出待认证的 agent 列表。这里可以看到 agent 的主机名。如 1puppet-agent-test-01 (66:62:5C:84:B0:23:73:FB:80:7C:89:48:4C:A6:AF:53) 然后可以使用 1puppet cert sign puppet-agent-test-01 就能完成认证。如果觉得直接使用主机名不够灵活，也可以在运行 agent 时使用 –certname=认证名 来指定。在 agent 端再试一次，这回就可以看到，agent 已经开始干活了。看看 bison 工具是否安装好了，再看看 /tmp 目录下是否生成了 /tmp/puppet-test 文件。 需要注意的是，一个主机可以使用多个不同的certname，但一个certname只能被一台主机使用。如果原有的certname需要移动到另一个主机上使用，就需要在master端先 puppet cert clean “ 认证名” 来清除原有数据。所以，certname应当尽量保持全局唯一。 这里 agent 使用的 –test 让 agent 不以服务方式运行，只执行一次，并输出详细信息。去掉这个参数，puppet agent 就会以服务方式在后台运行，默认每 30 分钟连接一次服务器更新配置。可以用 puppet help master、puppet help agent 查看更多选项。 刚才是把所有的配置都写在了 sites.pp 文件里。在配置项增多，维护的项目增多以后，就会变得过于庞大而难以维护。所以就需要把配置分到不同的模块中去，以模块化的方式来管理配置。 puppet 的模块放在 /etc/puppet/modules 下。模块的目录结构如下图所示： 1234567modules/|-- test |-- files | `-- test.txt `-- manifests |-- init.pp `-- test.pp 在这个例子里，定义了一个 test 模块。其中 files 目录中用于安放该模块所需分发的文件，manifests 目录中是该模块的配置文件。其中 init.pp 是每个模块的主配置文件。内容通常为 import “*” ，来载入该模块的其他配置文件。我们在 files 目录中加入一个 test.txt 文件，并把之前 site.pp 中的内容挪到 test.pp 中，再加入分发文件的配置，定义成一个类： 123456789101112class test1 &#123;package &#123; &quot;bison&quot;: ensure=&gt;&quot;installed&quot;,&#125;exec &#123; &quot;puppet test&quot;: command=&gt;&quot;/bin/touch /tmp/puppet-test&quot;,&#125;file &#123; &quot;/tmp/test.txt&quot;: ensure =&gt; &quot;present&quot;, source =&gt; &quot;puppet:///modules/test/test.txt&quot;&#125;&#125; site.pp 中删除原有的配置，加入 import “test” ，把 test 模块加载进来，然后加入 include “test1” ，应用 test1 类的配置。Include语句也可以再class内使用。以在一个class中复用另一个class的配置。现在，我们在 agent 端再运行一次 puppet agent –test ，agent 还是会照常工作，但是配置已经分到模块中了。实践中，会把每个配置的项目建立一个模块，比如：nginx、php 等等。再看看 /tmp 目录，会发现 master 端的 test.txt 文件已经下载回来。puppet 已经完成了文件分发的工作。module 中的 files 通常用于分发配置文件，把软件包的配置文件集中管理。 file配置也可以用来创建目录。只要使用 ensure =&gt; “directory” 即可。如： 123file &#123; &quot;/tmp/testdir&quot;: ensure =&gt; &quot;directory&quot;,&#125; 到目前为止，我们只使用了一个agent，实际环境中，会有许多台需要不同配置的 agent 。这就需要对不同的 agent 应用不同的配置。在 sites.pp 中把 include test1 替换成针对特定节点的配置： 1234import &quot;test&quot;node &quot;puppet-agent-test-01&quot; &#123; include &quot;test1&quot;&#125; 这里的主机名可以用 “,” 分隔，指定多个主机，也可以用类似 /puppet-agent-test-.*/ 这样的正则表达式来灵活匹配。为了测试配置是否生效，我们可以修改一下之前的配置，再运行一下 agent。还可以再加入几台 agent 试试应用不同的节点的不同配置。 之前加入 agent 时，需要在 master 端手动为 agent 认证。在客户端众多，或者需要完全自动化的时候，可以配置自动签名。当然，前提是能通过别的途径比如 iptables 限制访问 master 的来源，或者是在可信的内网环境下。 在 /etc/puppet 目录中添加 autosign.conf 中输入agent 认证名的模式，如 .test.net 。需要注意的是，这里必须使用类似泛域名通配符的方式。也就是说， 只能出现在前面，而不允许 test.* 这样的形式。所以要应用自动签名，在规划 agent 的认证名的时候就要注意这一点。现在，我们用 puppet agent –test –certname=”agent01.test.net” 试试。这回就不再需要手动认证，直接就能执行 master 分发的配置任务了。 实际应用puppet时，会把puppet的配置文件，以及要分发的软件包的配置文件都加入到svn等源代码管理中。但是我们也会需要用puppet来分发一些我们自己编译打包的软件包等二进制文件。这些二进制文件并不适合放进源代码管理中。另外，需要用puppet分发的证书、密钥等敏感信息也不适合放入。这时，使用模块的文件就不太方便。好在puppet的文件服务器也是可以配置的。建立puppet文件服务器配置文件：/etc/puppet/fileserver.conf，输入 123456[modules] allow *[files] path /data/puppet allow * 这就定义了一个名为files的额外文件服务挂载点，位于 /data/puppet。也放一个 test.txt 在里面，然后就可以使用 123file &#123; &quot;/tmp/test2.txt&quot;: source =&gt; &quot;puppet:///files/test.txt&quot;&#125; 来分发了。这里 puppet:// 是协议名，后面的路径 /files/test.txt 的第一部分是挂载点名称。之前使用的 modules 这个特殊的挂载点名是指向各个模块的文件。如 /modules/test/test.txt 就是test模块下files目录中的test.txt文件。而 /files/test.txt 就是 files 挂载点对应目录下的 test.txt 文件。之后，我们就可以把这些二进制文件等用别的途径部署到自定义挂载点上。 之前我们使用的file、exec、package 在puppet中都被称为资源。每一种资源都有许多参数可以设置。对于 file 资源，可以用 ensure =&gt; “link”, target =&gt; “目标路径” 来建立软链接，用mode=&gt;0644来设置文件访问权限。对于exec资源，可以用cwd参数来设置当前路径，用creates参数来设置执行命令创建的路径，可以用于防止重复执行命令。对于所有的资源类型，都有一些共有的参数，称为元参数。其中最常用的就是require参数。这个参数指定了这个资源所依赖的资源。实际应用中，不同的任务间会有依赖关系。比如安装软件包需要先创建好目标路径的目录，需要先安装好所需的依赖软件包，这就可以用require选项来实现。比如： 12345678exec &#123; &quot;install sth.&quot;: cwd =&gt; &quot;/opt/some_package&quot;, exec =&gt; &quot;/bin/tar -xzvf /path/to/package.tar.gz&quot;, require =&gt; File[&quot;/opt/some_package&quot;],&#125;file &#123; &quot;/opt/some_package&quot;: ensure =&gt; &quot;directory&quot;,&#125; 任务 Exec[“install sth.”] 就会在任务 File[“/opt/some_package”]完成后运行。这里，对于每个类型的资源，可以用“，”分隔；如果要指定多种类型的资源，也可以写成列表形式。如： 1require =&gt; [ File[&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;], Package[&quot;package1] ] 还有一个与require相反的参数before，可以指定该任务必须在哪些任务前完成。 puppet还提供了多种资源类型来完成不同的任务。比如可以用cron类型来管理定时任务，用host类型来设置hosts文件等。 至此，已经简单介绍了puppet 的基本功能设置，可以针对不同主机安装执行不同的所需任务。 puppet 还有更多强大的功能，您可以参照 puppet 的官方文档，各取所需，在实践中学习应用。 应用puppet，把原先繁琐的系统配置过程自动化了，需要部署一台新的服务器时，只需要在初始化好puppet后，执行一次 puppet agent –test，剩下的就交给它来干了。既省时省力也不会出错。 机械化的操作就应当交给机器来做，这样才能把人的精力省出来做更有价值的事情。 原文引自]]></content>
      <categories>
        <category>安全运维</category>
      </categories>
      <tags>
        <tag>puppet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL搭建主从复制实现细节分析]]></title>
    <url>%2F2017%2F12%2F09%2FMySQL%E6%90%AD%E5%BB%BA%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[概念 主从复制可以使MySQL数据库主服务器的主数据库，复制到一个或多个MySQL从服务器从数据库，默认情况下，复制异步; 根据配置，可以复制数据库中的所有数据库，选定的数据库或甚至选定的表。 MySQL中主从复制的优点横向扩展解决方案在多个从库之间扩展负载以提高性能。在这种环境中，所有写入和更新在主库上进行。但是，读取可能发生在一个或多个从库上。该模型可以提高写入的性能（由于主库专用于更新），同时在多个从库上读取，可以大大提高读取速度。 数据安全性由于主库数据被复制到从库，从库可以暂停复制过程，可以在从库上运行备份服务，而不会破坏对应的主库数据。 分析可以在主库上创建实时数据，而信息分析可以在从库上进行，而不会影响主服务器的性能。 长距离数据分发可以使用复制创建远程站点使用的数据的本地副本，而无需永久访问主库。 1.准备工作Mysql版本：MySQL 5.7.11Master-Server : 192.168.252.123Slave-Server : 192.168.252.124 关闭防火墙 1systemctl stop firewalld.service 安装 MySQL 首先在两台机器上装上，保证正常启动，可以使用 Master-Server 配置修改 my.cnf 配置 Master 以使用基于二进制日志文件位置的复制，必须启用二进制日志记录并建立唯一的服务器ID,否则则无法进行主从复制。 停止MySQL服务。 1service mysql.server stop 开启binlog ，每台设置不同的 server-id 1234$ cat /etc/my.cnf[mysqld]log-bin=mysql-binserver-id=1 启动MySQL服务 1service mysql.server start 登录MySQL 1/usr/local/mysql/bin/mysql -uroot -p 创建用户每个从库使用MySQL用户名和密码连接到主库，因此主库上必须有用户帐户，从库可以连接。任何帐户都可以用于此操作，只要它已被授予 REPLICATION SLAVE权限。可以选择为每个从库创建不同的帐户，或者每个从库使用相同帐户连接到主库 虽然不必专门为复制创建帐户，但应注意，复制用到的用户名和密码会以纯文本格式存储在主信息存储库文件或表中 。因此，需要创建一个单独的帐户，该帐户只具有复制过程的权限，以尽可能减少对其他帐户的危害。 登录MySQL 1/usr/local/mysql/bin/mysql -uroot -p 12mysql&gt; CREATE USER &apos;replication&apos;@&apos;192.168.252.124&apos; IDENTIFIED BY &apos;mima&apos;;mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;replication&apos;@&apos;192.168.252.124&apos;; Slave-Server 配置修改 my.cnf 停止MySQL服务。 1service mysql.server stop 123$ cat /etc/my.cnf[mysqld]server-id=2 如果要设置多个从库，则每个从库的server-id与主库和其他从库设置不同的唯一值。 启动MySQL服务 1service mysql.server start 登录MySQL 配置主库通信 查看 Master-Server ， binlog File 文件名称和 Position值位置 并且记下来 1mysql&gt; show master status; 要设置从库与主库进行通信，进行复制，使用必要的连接信息配置从库在从库上执行以下语句将选项值替换为与系统相关的实际值 参数格式，请勿执行 123456mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST=&apos;master_host_name&apos;, -&gt; MASTER_USER=&apos;replication_user_name&apos;, -&gt; MASTER_PASSWORD=&apos;replication_password&apos;, -&gt; MASTER_LOG_FILE=&apos;recorded_log_file_name&apos;, -&gt; MASTER_LOG_POS=recorded_log_position; 1234567mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST=&apos;192.168.252.123&apos;, -&gt; MASTER_USER=&apos;replication&apos;, -&gt; MASTER_PASSWORD=&apos;mima&apos;, -&gt; MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;, -&gt; MASTER_LOG_POS=629;Query OK, 0 rows affected, 2 warnings (0.02 sec) MASTER_LOG_POS=0 写成0 也是可以的 放在一行执行方便 1CHANGE MASTER TO MASTER_HOST=&apos;192.168.252.123&apos;, MASTER_USER=&apos;replication&apos;, MASTER_PASSWORD=&apos;mima&apos;, MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;, MASTER_LOG_POS=629; 启动从服务器复制线程 12mysql&gt; START SLAVE;Query OK, 0 rows affected (0.00 sec) 查看复制状态 检查主从复制通信状态 Slave_IO_State #从站的当前状态Slave_IO_Running： Yes #读取主程序二进制日志的I/O线程是否正在运行Slave_SQL_Running： Yes #执行读取主服务器中二进制日志事件的SQL线程是否正在运行。与I/O线程一样Seconds_Behind_Master #是否为0，0就是已经同步了 必须都是 Yes 在mysql5.0以后的版本，mysql主从已经相当的成熟了，可以只监控Slave_IO_Running，Slave_SQL_Running，Seconds_Behind_Master状态就可以了，这里不再做说明。 测试主从复制 启动MySQL服务 登录MySQL 在 Master-Server 创建测试库 123mysql&gt; CREATE DATABASE `replication_wwww.ymq.io`;mysql&gt; use `replication_wwww.ymq.io`;mysql&gt; CREATE TABLE `sync_test` (`id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; 在 Slave-Server 查看是否同步过来 123mysql&gt; show databases;mysql&gt; use replication_wwww.ymq.iomysql&gt; show tables; 一些坑 Last_IO_Errno: 1045错误： 解决方案 Connecting and Last_IO_Errno: 2003 错误 解决方案2 Last_Errno: 1008解决方案3 MySQL错误处理–1146错误 解决方案 Last_SQL_Errno：1062 解决方案 参考文档1 mysql主主和主主集群 双主同步，如果服务器意外挂机 MySQL基于日志（binlog）主从复制搭建 MySQL数据库设置主从同步]]></content>
      <categories>
        <category>安全运维</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu配置Shadowsocks实现终端代理]]></title>
    <url>%2F2017%2F12%2F09%2FUbuntu%E9%85%8D%E7%BD%AEShadowsocks%E5%AE%9E%E7%8E%B0%E7%BB%88%E7%AB%AF%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[背景场景一： 这几天想配置PHP Laravel框架，Laravel框架需要Composer安装。结果安装Composer的时候遭遇到了GFW，光在浏览器上穿墙还不够，还要在终端上穿墙。使用Shadowsocks在浏览器上穿墙很简单，但是在终端穿墙以前没接触过，这次花了5个小时搞定了。 利用linode翻墙安装相关配置时，哪速度，真是让人怀念。所以在局域网的一台机器上面开始动手了。 场景二： 做开发的同学，应该都会经常接触终端，有些时候我们在终端会做一些网络操作，比如下载gradle包等，由于一些你懂我也懂的原因，某些网络操作不是那么理想，这时候我们就需要设置代理来自由地访问网络。 Shadowsocks是我们常用的代理工具，它使用socks5协议，而终端很多工具目前只支持http和https等协议，对socks5协议支持不够好，所以我们为终端设置shadowsocks的思路就是将socks协议转换成http协议，然后为终端设置即可。仔细想想也算是适配器模式的一种现实应用吧。 想要进行转换，需要借助工具，这里我们采用比较知名的polipo来实现。 polipo是一个轻量级的缓存web代理程序。 前题是，已经在服务器端安装好了相关应用。 Shadowsocks 是一个开源安全的 Socks5 代理，中文名称“影梭“，类似于 SSH 代理。与一度非常流行的基于 GAE 的科学上网方式相比，Shadowsocks 部署简单，使用灵活；同时与全局代理的 VPN 不同，Shadowsocks 可以仅针对浏览器代理，轻巧方便，如果说 VPN 是一把 ==屠龙宝刀==，那么 Shadowsocks 就是一把 ==瑞士军刀==，虽小巧但功能强大。 1.ubuntu安装shadowsocks运行环境安装123sudo apt-get updatesudo apt-get install python-pipsudo apt-get install python-setuptools m2crypto 接着安装shadowsocks 1pip install shadowsocks 如果是ubuntu16.04 直接 (16.04 里可以直接用apt 而不用 apt-get 这是一项改进） 2.启动shadowsocks安装好后，在本地我们要用到sslocal ，终端输入sslocal –help 可以查看帮助，像这样 通过帮助提示我们知道各个参数怎么配置，比如 sslocal -c 后面加上我们的json配置文件，或者像下面这样直接命令参数写上运行。 比如 1sslocal -s 11.22.33.44 -p 50003 -k &quot;123456&quot; -l 1080 -t 600 -m aes-256-cfb -s表示服务IP, -p指的是服务端的端口，-l是本地端口默认是1080, -k 是密码（要加””）, -t超时默认300,-m是加密方法默认aes-256-cfb， 为了方便我推荐直接用sslcoal -c 配置文件路径 这样的方式，简单好用。 我们可以在/home/mudao/ 下新建个文件shadowsocks.json (mudao是我在我电脑上的用户名，这里路径你自己看你的)。内容是这样：12345678&#123;&quot;server&quot;:&quot;11.22.33.44&quot;,&quot;server_port&quot;:50003,&quot;local_port&quot;:1080,&quot;password&quot;:&quot;123456&quot;,&quot;timeout&quot;:600,&quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 确定上面的配置文件没有问题，然后我们就可以在终端输入 1sslocal -c /etc/shadowsocks.json 回车运行。如果没有问题的话，下面会是这样… 3.开机后台自动运行ss如果你上面可以代理上网了可以进行这一步，之前我让你不要关掉终端，因为关掉终端的时候代理就随着关闭了，之后你每次开机或者关掉终端之后，下次你再想用代理就要重新在终端输入这样的命令 sslocal -c /home/mudao/shadowsocks.json ，挺麻烦是不？ 我们现在可以在你的ubuntu上安装一个叫做supervisor的程序来管理你的sslocal启动。关于supervisor在前面介绍安装mod-ss-panel时，有介绍！ 1sudo apt-get install supervisor 安装好后我们可以在/etc/supervisor/目录下找到supervisor.conf配置文件，我们可以用以下命令来编辑 1sudo gedit /etc/supervisor/supervisor.conf 在这个文件的最后加上以下内容 1234567[program:shadowsocks]command=sslocal -c /home/mudao/shadowsocks.jsonautostart=trueautorestart=trueuser=rootlog_stderr=truelogfile=/var/log/shadowsocks.log 现在关掉你之前运行sslocal命令的终端，再打开终端输入 1sudo service supervisor restart 然后去打开浏览器看看可不可以继续代理上网。你也可以用 1ps -ef|grep sslocal 命令查看sslocal是否在运行。 这个时候我们需要在/etc下编辑一个叫rc.local的文件 ，让supervisor开机启动。 1sudo gedit /etc/rc.local 在这个配置文件的 1exit 0 前面一行加上 1service supervisor start 保存。 看你是否配置成功你可以在现在关机重启之后直接打开浏览器看是否代理成功。 以上原文引自这里4. 终端穿墙浏览器能穿墙就已经能满足绝大多数需求了，但是有的时候终端也必须穿墙，就比如Composer。关于终端穿墙，本人尝试了很多种方案，比如Privoxy、Proxychains和Polipo，最后选择了Privoxy。 为什么终端需要单独穿墙呢？难道Shadowsock不能“全局”代理么？这个问题当时困惑了我很久，最后一句话点醒了我。 Shadowsocks是一个使用SOCKS5（或者SOCK4之类）协议的代理，它只接受SOCKS5协议的流量，不接受HTTP或者HTTPS的流量。所以当你在Chrome上能穿墙的时候，是Proxy SwitchyOmega插件把HTTP和HTTPS流量转换成了SOCKS协议的流量，才实现了Shadowsocks的代理。而终端是没有这样的协议转换的，所以没法直接使用Shadowsock进行代理。 这时候就需要一个协议转换器，这里我用了Privoxy(我用privoxy没有成功！但是用polipo成功了)。 1~$ sudo apt-get install privoxy 安装好后进行配置，Privoxy的配置文件在/etc/privoxy/config，这个配置文件中注释很多。 找到 1listen-address 这一节，确认监听的端口号(这个端口号要跟1080区分开来，之前没有成功。估计就是因为把这个端口号改了)。 找到5.2. forward-socks4, forward-socks4a, forward-socks5 and forward-socks5t这一节，加上如下配置，注意最后的点号。 有关Privoxy的配置就结束了，重启一下Privoxy。 1~$ sudo /etc/init.d/privoxy restart 接着配置一下终端的环境，需要如下两句。 12~$ export http_proxy=&quot;127.0.0.1:8118&quot;~$ export https_proxy=&quot;127.0.0.1:8118&quot; 为了方便还是在/etc/rc.local中添加如下命令，注意在exit 0之前。 1sudo /etc/init.d/privoxy start 在/etc/profile的末尾添加如下两句。 12export http_proxy=&quot;127.0.0.1:8118&quot;export https_proxy=&quot;127.0.0.1:8118&quot; 安装privoxy的参考原文在这里 5.Shadowsocks 转换 HTTP 代理(使用Polipo)Shadowsocks 默认是用 Socks5 协议的，对于 ==Terminal== 的 get,wget 等走 Http 协议的地方是无能为力的，所以需要转换成 Http 代理，加强通用性，这里使用的转换方法是基于 Polipo 的。 输入命令安装 Polipo： 1sudo apt-get install polipo 修改配置文件： 1sudo gedit /etc/polipo/config 将下面的内容整个替换到文件中并保存： 123456789101112131415161718# This file only needs to list configuration variables that deviate# from the default values. See /usr/share/doc/polipo/examples/config.sample# and &quot;polipo -v&quot; for variables you can tweak and further information.logSyslog = falselogFile = &quot;/var/log/polipo/polipo.log&quot; socksParentProxy = &quot;127.0.0.1:1080&quot;socksProxyType = socks5 chunkHighMark = 50331648objectHighMark = 16384 serverMaxSlots = 64serverSlots = 16serverSlots1 = 32 proxyAddress = &quot;0.0.0.0&quot;proxyPort = 8123 重启 Polipo： 1/etc/init.d/polipo restart 验证代理是否正常工作： 12export http_proxy=&quot;http://127.0.0.1:8123/&quot;curl www.google.com 如果正常，就会返回抓取到的 Google 网页内容。 第二种验证代理是否正常工作的方法： 安装完成就需要进行验证是否work。这里展示一个最简单的验证方法，打开终端，如下执行 123407:56:24-androidyue/var/log$ curl ip.gs当前 IP：125.39.112.15 来自：中国天津天津 联通08:09:23-androidyue/var/log$ http_proxy=http://localhost:8123 curl ip.gs当前 IP：210.140.193.128 来自：日本日本 如上所示，为某个命令设置代理，前面加上http_proxy=http://localhost:8123 后接命令即可。注：8123是polipo的默认端口，如有需要，可以修改成其他有效端口。 当前会话全局设置如果嫌每次为每一个命令设置代理比较麻烦，可以为当前会话设置全局的代理。 即使用 1export http_proxy=http://localhost:8123 即可。 如果想撤销当前会话的http_proxy代理，使用 1unset http_proxy 1234567821:29:49-androidyue~$ curl ip.gs当前 IP：125.39.112.14 来自：中国天津天津 联通21:29:52-androidyue~$ export http_proxy=http://localhost:812321:30:07-androidyue~$ curl ip.gs当前 IP：210.140.193.128 来自：日本日本 21:30:12-androidyue~$ unset http_proxy21:30:37-androidyue~$ curl ip.gs当前 IP：125.39.112.14 来自：中国天津天津 联通 如果想要更长久的设置代理，可以将 12export http_proxy=http://localhost:8123export https_proxy=http://localhost:8123 加入.bashrc或者.bash_profile文件 另外，在浏览器中输入 1http://127.0.0.1:8123/ 便可以进入到 Polipo 的使用说明和配置界面。 设置浏览器和开机启动 最后就是将转换后的 Http 代理设置到浏览器中，地址是 127.0.0.1，端口 8123，代理类型当然是选择 Http 啦。对于 FireFor 用户来说，插件可以选择 AutoProxy 或 FoxyProxy 配置polipo在原文在这里 引申： 6.设置Git代理（接上面的polipo）复杂一些的设置Git代理 12345678git clone https://android.googlesource.com/tools/repo --config http.proxy=localhost:8123Cloning into &apos;repo&apos;...remote: Counting objects: 135, doneremote: Finding sources: 100% (135/135)remote: Total 3483 (delta 1956), reused 3483 (delta 1956)Receiving objects: 100% (3483/3483), 2.63 MiB | 492 KiB/s, done.Resolving deltas: 100% (1956/1956), done. 其实这样还是比较复杂，因为需要记忆的东西比较多， 下面是一个更简单的实现 首先，在.bashrc或者.bash_profile文件加入这一句。 1gp=&quot; --config http.proxy=localhost:8123&quot; 然后 执行source操作，更新当前bash配置。 更简单的使用git的方法 12345678git clone https://android.googlesource.com/tools/repo $gpCloning into &apos;repo&apos;...remote: Counting objects: 135, doneremote: Finding sources: 100% (135/135)remote: Total 3483 (delta 1956), reused 3483 (delta 1956)Receiving objects: 100% (3483/3483), 2.63 MiB | 483 KiB/s, done.Resolving deltas: 100% (1956/1956), done. [在git终端mac终端加入代理原文引自这里]http://droidyue.com/blog/2016/04/04/set-shadowsocks-proxy-for-terminal/) 7.apt-get怎么使用代理服务器升级到Ubuntu10.04后，发现apt-get的代理设置有改变了，在9.10以前使用“http_proxy”环境变量就可以令apt-get使用代理. 然后在Ubuntu10.04下就无效了，看来apt-get已经被改成不使用这个环境变量了。 一阵郁闷后，最后我发现在“首选项”-&gt;“网络代理”那里，多了个“System-wide”按钮（我用的是英文环境，不知道中文被翻译成怎样，关闭窗口时也会提示你），在这里设置后，apt-get确实可以使用代理了。 但是我依然鄙视这种改进，因为我通常就是偶尔使用代理，更新几个被墙掉的仓库而已（如dropbox和tor），根本不想使用全局代理，本来用终端就能搞定的事，现在切换代理要点N次鼠标，真烦。 所以我研究了一下，发现那个代理设置修改了两个文件，一个是“/etc/environment”，这个是系统的环境变量，里面定义了“http_proxy”等代理环境变量。另一个是“/etc/apt/apt.conf”，这个就是apt的配置，内容如下 在/etc/apt/apt.conf中追加 123Acquire::http::proxy &quot;http://127.0.0.1:8123/&quot;;Acquire::ftp::proxy &quot;ftp://127.0.0.1:8123/&quot;;Acquire::https::proxy &quot;https://127.0.0.1:8123/&quot;; 很明显的代理设置代码，我看了下apt-get的手册，发现可以用“-c”选项来指定使用配置文件，也就是复制一份为“~/apt_proxy.conf”，然后“网络代理”那里重置回直接连接，以后使用 1sudo apt-get -c ~/apt_proxy.conf update 1sudo apt-get -c ~/apt_proxy.conf install mongodb apt-get 使用代理在的原文在这里]]></content>
      <categories>
        <category>科学上网</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo + Github Pages搭建个人独立博客]]></title>
    <url>%2F2017%2F12%2F08%2F%E4%BD%BF%E7%94%A8Hexo-Github-Pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[系统环境配置要使用Hexo，需要在你的系统中支持Nodejs以及Git 安装Hexo1234567$ cd d:/hexo$ npm install hexo-cli -g$ hexo init blog$ cd blog$ npm install$ hexo g # 或者hexo generate$ hexo s # 或者hexo server，可以在http://localhost:4000/ 查看 这里有必要提下Hexo常用的几个命令：12$ hexo new &quot;postName&quot; #新建文章$ hexo new page &quot;pageName&quot; #新建页面 常用简写1234$ hexo n == hexo new$ hexo g == hexo generate$ hexo s == hexo server$ hexo d == hexo deploy 123hexo generate (hexo g) 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹hexo server (hexo s) 启动本地web服务，用于博客的预览hexo deploy (hexo d) 部署播客到远端（比如github, heroku等平台） 常用组合12$ hexo d -g #生成部署$ hexo s -g #生成预览 Hexo主题设置 Github Pages设置 什么是Github Pages GitHub Pages 本用于介绍托管在GitHub的项目，不过，由于他的空间免费稳定，用来做搭建一个博客再好不过了。 每个帐号只能有一个仓库来存放个人主页，而且仓库的名字必须是username/username.github.io，这是特殊的命名约定。你可以通过http://username.github.io 来访问你的个人主页。 这里特别提醒一下，需要注意的个人主页的网站内容是在master分支下的。 部署Hexo到Github Pages 首先需要明白所谓部署到github的原理。 之前步骤中在Github上创建的那个特别的repo（jiji262.github.io）一个最大的特点就是其master中的html静态文件，可以通过链接http://jiji262.github.io来直接访问。 Hexo -g 会生成一个静态网站（第一次会生成一个public目录），这个静态文件可以直接访问。需要将hexo生成的静态网站，提交(git commit)到github上。明白了原理，怎么做自然就清晰了. 使用hexo deploy部署hexo deploy可以部署到很多平台，具体可以参考这个链接. 如果部署到github，需要在配置文件_config.xml中作如下修改： 1234deploy: type: git repo: git@github.com:jiji262/jiji262.github.io.git branch: master 然后在命令行中执行 1hexo d 即可完成部署。 踩坑提醒 注意需要提前安装一个扩展： 1$ npm install hexo-deployer-git --save Hexo 主题配置参考文档1]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F12%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
